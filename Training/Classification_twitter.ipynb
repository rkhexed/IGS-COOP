{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c91ac95-4ad6-4188-9e01-09b7f566633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import nltk \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5138bb6-1f74-40f7-8b81-b0516bb8987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"Corona_NLP_train.csv\",encoding='latin1')\n",
    "test=pd.read_csv(\"Corona_NLP_test.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b621a0-4db4-49ae-b8d5-5e1a30f6f1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    0.438467\n",
       "0    0.374128\n",
       "1    0.187404\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = train.OriginalTweet\n",
    "train[\"text\"] = train[\"text\"].astype(str)\n",
    "\n",
    "test['text'] = test.OriginalTweet\n",
    "test[\"text\"] = test[\"text\"].astype(str)\n",
    "\n",
    "# Data has 5 classes, let's convert them to 3\n",
    "\n",
    "def classes_def(x):\n",
    "    if x ==  \"Extremely Positive\":\n",
    "        return \"2\"\n",
    "    elif x == \"Extremely Negative\":\n",
    "        return \"0\"\n",
    "    elif x == \"Negative\":\n",
    "        return \"0\"\n",
    "    elif x ==  \"Positive\":\n",
    "        return \"2\"\n",
    "    else:\n",
    "        return \"1\"\n",
    "    \n",
    "\n",
    "train['label']=train['Sentiment'].apply(lambda x:classes_def(x))\n",
    "test['label']=test['Sentiment'].apply(lambda x:classes_def(x))\n",
    "\n",
    "\n",
    "train.label.value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20fb1c83-08f5-4efb-8f78-eb02781a4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Urls and HTML links\n",
    "def remove_urls(text):\n",
    "    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_remove.sub(r'', text)\n",
    "train['text_new']=train['text'].apply(lambda x:remove_urls(x))\n",
    "test['text_new']=test['text'].apply(lambda x:remove_urls(x))\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "train['text']=train['text_new'].apply(lambda x:remove_html(x))\n",
    "test['text']=test['text_new'].apply(lambda x:remove_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9897769b-ef1b-4f3a-9bad-5af6eacb773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['a', 'an', 'the']\n",
    "\n",
    "# Basic cleansing\n",
    "def cleansing(text):\n",
    "    # Tokenize\n",
    "    tokens = text.split(' ')\n",
    "    # Lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # Remove stop words\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# All-in-one preproce\n",
    "def preprocess_x(x):\n",
    "    processed_x = [cleansing(text) for text in x]\n",
    "    \n",
    "    return processed_x\n",
    "\n",
    "train['text_new']=train['text'].apply(lambda x:preprocess_x(x))\n",
    "test['text_new']=test['text'].apply(lambda x:preprocess_x(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a9adf6-e44c-462e-a4c5-6410568ae06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower casing\n",
    "def lower(text):\n",
    "    low_text= text.lower()\n",
    "    return low_text\n",
    "train['text_new']=train['text'].apply(lambda x:lower(x))\n",
    "test['text_new']=test['text'].apply(lambda x:lower(x))\n",
    "\n",
    "\n",
    "# Number removal\n",
    "def remove_num(text):\n",
    "    remove= re.sub(r'\\d+', '', text)\n",
    "    return remove\n",
    "train['text']=train['text_new'].apply(lambda x:remove_num(x))\n",
    "test['text']=test['text_new'].apply(lambda x:remove_num(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f1b8ef5-3c10-4070-8bdf-794ebdaae60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords & Punctuations\n",
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def punct_remove(text):\n",
    "    punct = re.sub(r\"[^\\w\\s\\d]\",\"\", text)\n",
    "    return punct\n",
    "train['text_new']=train['text'].apply(lambda x:punct_remove(x))\n",
    "test['text_new']=test['text'].apply(lambda x:punct_remove(x))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "train['text']=train['text_new'].apply(lambda x:remove_stopwords(x))\n",
    "test['text']=test['text_new'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7bca82a-94af-4bb2-b7d3-4bbd6cb40a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove mentions and hashtags\n",
    "def remove_mention(x):\n",
    "    text=re.sub(r'@\\w+','',x)\n",
    "    return text\n",
    "train['text_new']=train['text'].apply(lambda x:remove_mention(x))\n",
    "test['text_new']=test['text'].apply(lambda x:remove_mention(x))\n",
    "\n",
    "def remove_hash(x):\n",
    "    text=re.sub(r'#\\w+','',x)\n",
    "    return text\n",
    "train['text']=train['text_new'].apply(lambda x:remove_hash(x))\n",
    "test['text']=test['text_new'].apply(lambda x:remove_hash(x))\n",
    "\n",
    "#Remove extra white space left while removing stuff\n",
    "def remove_space(text):\n",
    "    space_remove = re.sub(r\"\\s+\",\" \",text).strip()\n",
    "    return space_remove\n",
    "train['text_new']=train['text'].apply(lambda x:remove_space(x))\n",
    "test['text_new']=test['text'].apply(lambda x:remove_space(x))\n",
    "test = test.drop(columns=['text_new'])\n",
    "train = train.drop(columns=['text_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bb8119d-8127-43e7-b4c2-6b9a25d6cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[\"text\"].tolist()\n",
    "y = train[\"label\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.10,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "321a4853-301f-4606-b289-3d1b3972204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the 41157 tweets is represented by 10615 features (TF-IDF score of unigrams and bigrams)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                    \n",
    "                        stop_words='english')\n",
    "\n",
    "# We transform each text into a vector\n",
    "features = tfidf.fit_transform(train.text).toarray()\n",
    "\n",
    "labels = train.label\n",
    "\n",
    "print(\"Each of the %d tweets is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39d6ec5c-81f9-430c-9b7a-576d6f297a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "]\n",
    "\n",
    "# 5 Cross-validation\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be79eb8a-2ad7-4c2f-9fde-06e478fb1cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.784411</td>\n",
       "      <td>0.004532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.659791</td>\n",
       "      <td>0.003452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.470029</td>\n",
       "      <td>0.003683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Accuracy  Standard deviation\n",
       "model_name                                               \n",
       "LinearSVC                    0.784411            0.004532\n",
       "MultinomialNB                0.659791            0.003452\n",
       "RandomForestClassifier       0.470029            0.003683"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "std_accuracy = cv_df.groupby('model_name').accuracy.std()\n",
    "\n",
    "acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n",
    "          ignore_index=True)\n",
    "acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11fe2499-44c3-4d46-a7cd-b8fa9be9867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test,indices_train,indices_test = train_test_split(features, \n",
    "                                                               labels, \n",
    "                                                               train.index, test_size=0.10, \n",
    "                                                               random_state=1)\n",
    "model =   LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "436649cc-0144-47db-ba22-2940177f1b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tCLASSIFICATIION METRICS\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.79      0.80      1554\n",
      "           2       0.69      0.67      0.68       760\n",
      "           0       0.82      0.84      0.83      1802\n",
      "\n",
      "    accuracy                           0.79      4116\n",
      "   macro avg       0.77      0.77      0.77      4116\n",
      "weighted avg       0.79      0.79      0.79      4116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "print('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
    "print(metrics.classification_report(y_test, y_pred, \n",
    "                                    target_names= train['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b5b2631-648b-4d71-ba68-0374b02c56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,indices_train,indices_test = train_test_split(features, \n",
    "                                                               labels, \n",
    "                                                               train.index, test_size=0.10, \n",
    "                                                               random_state=1)\n",
    "model =   MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf61c559-68ba-424f-bbaf-78012ef3814f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tCLASSIFICATIION METRICS\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.71      0.70      1554\n",
      "           2       0.72      0.17      0.28       760\n",
      "           0       0.64      0.84      0.73      1802\n",
      "\n",
      "    accuracy                           0.67      4116\n",
      "   macro avg       0.69      0.57      0.57      4116\n",
      "weighted avg       0.68      0.67      0.64      4116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "print('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
    "print(metrics.classification_report(y_test, y_pred, \n",
    "                                    target_names= train['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e053df72-a2af-4b27-8f48-e804a04c3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,indices_train,indices_test = train_test_split(features, \n",
    "                                                               labels, \n",
    "                                                               train.index, test_size=0.10, \n",
    "                                                               random_state=1)\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ba27571-eefa-4338-8679-8f93c51d1a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tCLASSIFICATIION METRICS\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.08      0.15      1554\n",
      "           2       0.00      0.00      0.00       760\n",
      "           0       0.45      1.00      0.62      1802\n",
      "\n",
      "    accuracy                           0.47      4116\n",
      "   macro avg       0.46      0.36      0.26      4116\n",
      "weighted avg       0.55      0.47      0.33      4116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "print('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
    "print(metrics.classification_report(y_test, y_pred, \n",
    "                                    target_names= train['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fab54-b7dc-44de-9f9e-4b00c3e9d328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
