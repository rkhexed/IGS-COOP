{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05323c82-b757-41ff-8b03-5f73ce49d039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/rohanrao/nifty50-stock-market-data?dataset_version_number=15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 18.4M/18.4M [00:02<00:00, 7.79MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/kaushal/.cache/kagglehub/datasets/rohanrao/nifty50-stock-market-data/versions/15\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - loss: 3.3677e-04 - val_loss: 5.9057e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7ms/step - loss: 1.8907e-04 - val_loss: 1.1767e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.6851e-04 - val_loss: 1.4840e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.6166e-04 - val_loss: 2.7630e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.5629e-04 - val_loss: 2.0734e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.5466e-04 - val_loss: 2.8444e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.5156e-04 - val_loss: 2.2341e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.4666e-04 - val_loss: 3.2460e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.4829e-04 - val_loss: 4.4657e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.4270e-04 - val_loss: 5.3588e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 8.2696e-04 - val_loss: 3.4300e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7ms/step - loss: 2.5476e-04 - val_loss: 5.4440e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.7435e-04 - val_loss: 4.3291e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.7140e-04 - val_loss: 4.2488e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.7803e-04 - val_loss: 8.4746e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m781s\u001b[0m 133ms/step - loss: 1.6417e-04 - val_loss: 8.0650e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - loss: 1.5373e-04 - val_loss: 0.0011\n",
      "Epoch 18/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 7ms/step - loss: 1.6606e-04 - val_loss: 8.1483e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7ms/step - loss: 1.6327e-04 - val_loss: 7.7515e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 7ms/step - loss: 1.5821e-04 - val_loss: 9.5563e-04\n",
      "Epoch 1/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 17ms/step - loss: 4.9159e-04 - val_loss: 8.4955e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 16ms/step - loss: 1.5320e-04 - val_loss: 1.3305e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 16ms/step - loss: 1.4871e-04 - val_loss: 3.2378e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 18ms/step - loss: 1.2715e-04 - val_loss: 5.3004e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 21ms/step - loss: 1.3728e-04 - val_loss: 6.0592e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 17ms/step - loss: 1.2186e-04 - val_loss: 8.1448e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 15ms/step - loss: 1.2785e-04 - val_loss: 8.2599e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 16ms/step - loss: 1.2432e-04 - val_loss: 0.0011\n",
      "Epoch 9/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 17ms/step - loss: 1.2115e-04 - val_loss: 0.0012\n",
      "Epoch 10/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 17ms/step - loss: 1.1364e-04 - val_loss: 0.0015\n",
      "Epoch 11/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 17ms/step - loss: 1.0738e-04 - val_loss: 0.0015\n",
      "Epoch 12/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 16ms/step - loss: 1.1204e-04 - val_loss: 0.0019\n",
      "Epoch 13/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 16ms/step - loss: 1.1546e-04 - val_loss: 0.0022\n",
      "Epoch 14/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 17ms/step - loss: 1.0123e-04 - val_loss: 0.0023\n",
      "Epoch 15/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 17ms/step - loss: 1.0051e-04 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 17ms/step - loss: 1.0514e-04 - val_loss: 0.0026\n",
      "Epoch 17/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 16ms/step - loss: 9.8668e-05 - val_loss: 0.0027\n",
      "Epoch 18/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 17ms/step - loss: 9.8471e-05 - val_loss: 0.0028\n",
      "Epoch 19/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 16ms/step - loss: 1.0470e-04 - val_loss: 0.0028\n",
      "Epoch 20/20\n",
      "\u001b[1m5879/5879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 17ms/step - loss: 1.0009e-04 - val_loss: 0.0033\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step\n",
      "RNN Predictions: [[2752.6853 ]\n",
      " [ 965.5146 ]\n",
      " [ 891.00995]\n",
      " [3054.3752 ]\n",
      " [ 744.05444]]\n",
      "LSTM Predictions: [[3073.6057]\n",
      " [2415.0603]\n",
      " [2312.1292]\n",
      " [3092.1782]\n",
      " [2121.615 ]]\n",
      "Actual Values: [[1165.4 ]\n",
      " [ 482.  ]\n",
      " [ 351.15]\n",
      " [1193.9 ]\n",
      " [ 166.95]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Dropout\n",
    "import kagglehub\n",
    "\n",
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"rohanrao/nifty50-stock-market-data\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Load dataset\n",
    "# Assuming the main file is 'NIFTY50_all.csv' based on the dataset description\n",
    "\n",
    "# Preprocess data\n",
    "# Use 'Close' column as the target for prediction\n",
    "data = df['Close'].values.reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Create sequences for time series prediction\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data[i-seq_length:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 60  # Predict based on the last 60 days\n",
    "X, y = create_sequences(data_scaled, sequence_length)\n",
    "\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))  # Reshape for RNN/LSTM\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RNN Model\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(50, activation='relu', return_sequences=True, input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(50, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "rnn_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Define LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions\n",
    "rnn_pred = rnn_model.predict(X_test)\n",
    "lstm_pred = lstm_model.predict(X_test)\n",
    "\n",
    "# Reverse scaling\n",
    "rnn_pred = scaler.inverse_transform(rnn_pred)\n",
    "lstm_pred = scaler.inverse_transform(lstm_pred)\n",
    "y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Evaluate\n",
    "print(\"RNN Predictions:\", rnn_pred[:5])\n",
    "print(\"LSTM Predictions:\", lstm_pred[:5])\n",
    "print(\"Actual Values:\", y_test_original[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe2d314-0d54-4b84-8f07-45f7dbde3791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/kaushal/.cache/kagglehub/datasets/rohanrao/nifty50-stock-market-data/versions/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.0012 - val_loss: 1.5606e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 3.4456e-04 - val_loss: 1.3829e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 3.1583e-04 - val_loss: 1.8756e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.5929e-04 - val_loss: 2.6854e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 3.3363e-04 - val_loss: 4.2251e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.6075e-04 - val_loss: 3.3486e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.2649e-04 - val_loss: 5.1453e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.7133e-04 - val_loss: 5.2605e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.5931e-04 - val_loss: 5.1526e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.5015e-04 - val_loss: 7.2350e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.3171e-04 - val_loss: 5.6862e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.3174e-04 - val_loss: 5.5519e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.2949e-04 - val_loss: 7.2277e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.4007e-04 - val_loss: 8.5570e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.2708e-04 - val_loss: 8.6193e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.2757e-04 - val_loss: 6.0566e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.1878e-04 - val_loss: 8.7029e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.4613e-04 - val_loss: 0.0012\n",
      "Epoch 19/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.6103e-04 - val_loss: 9.3629e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 2.4398e-04 - val_loss: 0.0011\n",
      "Epoch 1/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 16ms/step - loss: 6.3013e-04 - val_loss: 8.6622e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 2.5643e-04 - val_loss: 6.6658e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 15ms/step - loss: 2.3013e-04 - val_loss: 8.4675e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - loss: 2.1721e-04 - val_loss: 1.0705e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 2.0970e-04 - val_loss: 1.1985e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 15ms/step - loss: 2.1444e-04 - val_loss: 1.4455e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.7965e-04 - val_loss: 1.9954e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 15ms/step - loss: 1.9951e-04 - val_loss: 2.7407e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.7076e-04 - val_loss: 2.1650e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.6777e-04 - val_loss: 2.1115e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.9262e-04 - val_loss: 2.2190e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.9594e-04 - val_loss: 1.4619e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 2.0869e-04 - val_loss: 2.5053e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.7491e-04 - val_loss: 2.6611e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.6873e-04 - val_loss: 2.0218e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.8515e-04 - val_loss: 2.8223e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.7068e-04 - val_loss: 3.6170e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 1.6341e-04 - val_loss: 2.6807e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 16ms/step - loss: 1.5414e-04 - val_loss: 2.8871e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m3008/3008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 1.6302e-04 - val_loss: 4.0418e-04\n",
      "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m752/752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "RNN Predictions: [[5912.6704]\n",
      " [1124.6409]\n",
      " [3731.072 ]\n",
      " [1141.2552]\n",
      " [3549.0156]]\n",
      "LSTM Predictions: [[4464.3413 ]\n",
      " [ 929.58405]\n",
      " [3440.2407 ]\n",
      " [ 940.7165 ]\n",
      " [3338.249  ]]\n",
      "Actual Values: [[3579.9 ]\n",
      " [ 355.2 ]\n",
      " [2603.8 ]\n",
      " [ 365.95]\n",
      " [2445.85]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Dropout\n",
    "import kagglehub\n",
    "\n",
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"rohanrao/nifty50-stock-market-data\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Load dataset\n",
    "dataset_file = f\"{path}/NIFTY50_all.csv\"\n",
    "df = pd.read_csv(dataset_file)\n",
    "\n",
    "# Select relevant columns\n",
    "features = ['Prev Close', 'Open', 'High', 'Low', 'Last', 'VWAP', 'Volume', \n",
    "            'Turnover', 'Trades', 'Deliverable Volume', '%Deliverble', 'Close']\n",
    "df = df[features]\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "target_column = 'Close'\n",
    "X_raw = df.drop(columns=[target_column])\n",
    "y_raw = df[target_column].values.reshape(-1, 1)\n",
    "\n",
    "# Scale features and target\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X_raw)\n",
    "y_scaled = scaler_y.fit_transform(y_raw)\n",
    "\n",
    "# Create sequences for time series prediction\n",
    "def create_sequences(data, target, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data[i-seq_length:i])  # Sequence of features\n",
    "        y.append(target[i])            # Corresponding target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 60  # Use the last 60 timesteps\n",
    "X, y = create_sequences(X_scaled, y_scaled, sequence_length)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RNN Model\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(50, activation='relu', return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(50, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "rnn_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Define LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predictions\n",
    "rnn_pred = rnn_model.predict(X_test)\n",
    "lstm_pred = lstm_model.predict(X_test)\n",
    "\n",
    "# Reverse scaling\n",
    "rnn_pred = scaler_y.inverse_transform(rnn_pred)\n",
    "lstm_pred = scaler_y.inverse_transform(lstm_pred)\n",
    "y_test_original = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"RNN Predictions:\", rnn_pred[:5])\n",
    "print(\"LSTM Predictions:\", lstm_pred[:5])\n",
    "print(\"Actual Values:\", y_test_original[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a298647a-e513-4b61-ad9d-c168b96bb604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Symbol', 'Series', 'Prev Close', 'Open', 'High', 'Low', 'Last',\n",
       "       'Close', 'VWAP', 'Volume', 'Turnover', 'Trades', 'Deliverable Volume',\n",
       "       '%Deliverble'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = f\"{path}/NIFTY50_all.csv\"\n",
    "df = pd.read_csv(dataset_file)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf67912d-0bf0-460d-8bd8-3151bedd8e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf82a1c6e4749b7bdff889ee1ac34f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358c3fd5d3ce43f4a87da9ae327a61c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129094eaa8b74b6597fefb019af34ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491d740ababb4f81b5100aab33f59e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e73248320444e1a66ab7b397aecff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8a85181a2342edb18d4a533947e5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography?\n",
      "\n",
      "Answer: Let's think step by step.I'm not a neuroscientist, but I'm pretty sure it's a branch of neuroscience.\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)\n",
    "\n",
    "\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"microsoft/DialoGPT-medium\", task=\"text-generation\", pipeline_kwargs={\"max_new_tokens\": 200, \"pad_token_id\": 50256},\n",
    ")\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | hf\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e679681-9afe-487e-87a9-b274754d3d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (3.9.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.8 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.3.8)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.3.21)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.1.145)\n",
      "Requirement already satisfied: numpy<2,>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.32.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (2.10.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (2.27.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.8 marshmallow-3.23.1 pydantic-settings-2.6.1 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d825a0-fc29-4f18-b9d4-9d58435b1e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
