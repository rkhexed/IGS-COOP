{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa7d45f-59e5-4987-a421-825d6d359aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"main.py\"\n",
    "\n",
    "from pymilvus import MilvusClient, model\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "from feature_extraction import main_feature # closest_features  \n",
    "import re, sys\n",
    "from bson.objectid import ObjectId\n",
    "from model import model_response\n",
    "\n",
    "mongodb_uri = \"mongodb://localhost:27018\"\n",
    "embedding_fn = model.DefaultEmbeddingFunction()\n",
    "milvus_client = MilvusClient(\"../data/milvus_demo.db\")\n",
    "\n",
    "def user_stories_db(database_name, collection_name, milvus_collection_name):\n",
    "    mongo_client = MongoClient(mongodb_uri)\n",
    "    db = mongo_client[database_name]\n",
    "    collection = db[collection_name]\n",
    "    documents = collection.find()\n",
    "\n",
    "    milvus_client.drop_collection(collection_name=milvus_collection_name)\n",
    "    milvus_client.create_collection(collection_name=milvus_collection_name, dimension=768)\n",
    "\n",
    "    story_data, complete_data = [], []\n",
    "\n",
    "    # Iterate over the MongoDB data\n",
    "    for doc in tqdm(documents):\n",
    "        try:\n",
    "            if \"refined\" not in doc or not doc[\"refined\"]:\n",
    "                doc[\"refined\"] = \" \"\n",
    "        \n",
    "            story_data.append(doc[\"story\"]+doc[\"refined\"])\n",
    "            complete_data.append({\"text\":doc[\"story\"]+doc[\"refined\"], \"id\":doc[\"_id\"]})\n",
    "        except:\n",
    "            print(\"Error with schema\")\n",
    "            #sys.exit()\n",
    "    # Convert the data to vectors\n",
    "    vectors = embedding_fn.encode_documents(story_data)\n",
    "    data = [{\"id\":i, \"data_id\":complete_data[i][\"id\"], \"vector\":vectors[i], \"text\":complete_data[i][\"text\"]} for i in range(len(vectors))]\n",
    "    \n",
    "    # Store the vector in Milvus\n",
    "    milvus_client.insert(collection_name = milvus_collection_name, data = data)\n",
    "\n",
    "\n",
    "def retrieve_user_stories(query, milvus_collection_name, threshold):\n",
    "    query_vectors = embedding_fn.encode_queries([query])\n",
    "    results = milvus_client.search(collection_name = milvus_collection_name, params = {\"radius\":threshold}, data=query_vectors, output_fields=[\"data_id\", \"text\", \"id\"])    \n",
    "    \n",
    "    mongo_ids = []\n",
    "    # Get list of IDs from MongoDB\n",
    "    for i in range(len(results[0])):\n",
    "        val = results[0][i][\"entity\"][\"data_id\"]\n",
    "        mongo_ids.append(val)\n",
    "    \n",
    "    print(\"Number of matching user story\", len(mongo_ids))\n",
    "\n",
    "    return mongo_ids\n",
    "\n",
    "def metadata_retrieval(database_name, collection_name, query, mongo_user_story_ids):\n",
    "    main_app_keys = main_feature(query) #closest_features(query)\n",
    "    \"\"\"\n",
    "    query_keys = [\"story\"] + main_app_keys\n",
    "    projection1 = {field: 1 for field in query_keys}\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the basic MongoQuery Dynamically\n",
    "    projection2 = {}\n",
    "    for field, subfields in main_app_keys.items():\n",
    "        if subfields:\n",
    "            for subfield in subfields:\n",
    "                projection2[f\"{field}.{subfield}\"] = 1\n",
    "        else:\n",
    "            projection2[f\"{field}\"] = 1\n",
    "        projection2[\"story\"] = 1 \n",
    "        projection2[\"refined\"] = 1\n",
    "    print(\"The mongoquery : \", projection2)\n",
    "    \n",
    "    # Use the mongo queries on the identified user story IDs\n",
    "    def match_mongo():\n",
    "        chunk_data = []\n",
    "        mongo_client = MongoClient(mongodb_uri)\n",
    "        db = mongo_client[database_name]\n",
    "        collection = db[collection_name]\n",
    "        \n",
    "        stories = collection.find({ '_id': { '$in':  mongo_user_story_ids} }, projection2)\n",
    "        \n",
    "\n",
    "        for i in stories:\n",
    "            temp_data = \"\"\n",
    "            for k in i.keys():\n",
    "                if k==\"_id\" or k==\"status\":\n",
    "                    continue\n",
    "                if k == \"story\":\n",
    "                    temp_data += f\"User story - {i[k]} \\t\"\n",
    "                if k==\"refined\":\n",
    "                    temp_data += f\"Refined User story - {i[k]} \\t\"\n",
    "                value = re.sub(r'[^a-zA-Z0-9\\s]',\"\", str(i[k]))\n",
    "                temp_data += f\"{k.upper()} - {value}. \\t\"\n",
    "            chunk_data.append(temp_data)\n",
    "        return chunk_data\n",
    "\n",
    "    chunks = match_mongo()\n",
    "    return chunks\n",
    "def main():\n",
    "    database_name = \"OrgqrS1HZ\"\n",
    "    collection_name = \"userStories\"\n",
    "    milvus_collection_name = \"temp\" \n",
    "    check = \"T\"\n",
    "    # Get the user story IDs from Mongo DB\n",
    "    #user_stories_db(database_name, collection_name, milvus_collection_name)\n",
    "    \n",
    "    while check==\"T\":\n",
    "        query = input(\"Enter query : \") #what are the functional test scenarios for emails\"\n",
    "        mongo_user_story_ids = retrieve_user_stories(query, milvus_collection_name, 0.2)\n",
    "        mongo_user_story_ids = list(set(mongo_user_story_ids[:5])) # Take first 5 unique IDs\n",
    "\n",
    "        # Get keys from metadata base on query\n",
    "        chunk_data = metadata_retrieval(database_name, collection_name, query, mongo_user_story_ids) \n",
    "        #print(\"The chunked data is :\",chunk_data) \n",
    "\n",
    "        # Get Model Response\n",
    "        response = model_response(query, \"\\n\".join(chunk_data))\n",
    "        print(\"Model response:\\n\",response)\n",
    "        \n",
    "        check = input(\"Continue [T/F] : \")\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675def3e-842e-43f7-a5c1-1a1abe69d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Auto-Tester\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Function to handle file-based querying and store results in a CSV\n",
    "def query_and_store_results(input_file, output_csv, database_name, collection_name, milvus_collection_name):\n",
    "    results = []\n",
    "\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            query = line\n",
    "\n",
    "        # Query the RAG model\n",
    "        mongo_user_story_ids = retrieve_user_stories(query, milvus_collection_name, 0.2)\n",
    "        mongo_user_story_ids = list(set(mongo_user_story_ids[:5]))  # Take first 5 unique IDs\n",
    "        chunk_data = metadata_retrieval(database_name, collection_name, query, mongo_user_story_ids)\n",
    "        response = model_response(query, \"\\n\".join(chunk_data))\n",
    "        results.append({'Query': query, 'Response': response})\n",
    "\n",
    "        # Check if the next line is empty to determine \"T\" or \"F\" input\n",
    "        if i + 1 < len(lines) and lines[i + 1].strip() != \"\":\n",
    "            response_t = model_response(\"T\", \"\\n\".join(chunk_data))\n",
    "            results.append({'Query': \"T\", 'Response': response_t})\n",
    "        else:\n",
    "            response_f = model_response(\"F\", \"\\n\".join(chunk_data))\n",
    "            results.append({'Query': \"F\", 'Response': response_f})\n",
    "            break\n",
    "\n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff1232-4e4f-4c44-835c-7dc60d358935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Post test ROUGE Score\"\n",
    "\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Function to update CSV with ROUGE scores between expected and RAG response and print them\n",
    "def update_csv_with_rouge_scores(input_csv, output_csv):\n",
    "    # Load the CSV containing Queries, Responses, and Expected Responses\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Initialize the ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Lists to hold the ROUGE scores\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "\n",
    "    # Calculate ROUGE scores for each pair of response and expected response\n",
    "    for i, row in df.iterrows():\n",
    "        expected = row['Expected Responses']\n",
    "        response = row['Response']\n",
    "        \n",
    "        # Compute ROUGE scores\n",
    "        scores = scorer.score(expected, response)\n",
    "        \n",
    "        # Append the scores to respective lists\n",
    "        rouge1 = scores['rouge1'].fmeasure\n",
    "        rouge2 = scores['rouge2'].fmeasure\n",
    "        rougeL = scores['rougeL'].fmeasure\n",
    "        rouge1_scores.append(rouge1)\n",
    "        rouge2_scores.append(rouge2)\n",
    "        rougeL_scores.append(rougeL)\n",
    "        \n",
    "        # Print the ROUGE scores for this row\n",
    "        print(f\"Row {i+1}: ROUGE-1: {rouge1:.4f}, ROUGE-2: {rouge2:.4f}, ROUGE-L: {rougeL:.4f}\")\n",
    "\n",
    "    # Add the scores as new columns in the DataFrame\n",
    "    df['ROUGE-1'] = rouge1_scores\n",
    "    df['ROUGE-2'] = rouge2_scores\n",
    "    df['ROUGE-L'] = rougeL_scores\n",
    "    \n",
    "    # Save the updated DataFrame with ROUGE scores to a new CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Updated CSV with ROUGE scores saved as {output_csv}\")\n",
    "\n",
    "# Usage\n",
    "input_csv = 'path/to/updated_results.csv'  # CSV with Query, Response, Expected Responses\n",
    "output_csv = 'path/to/final_results_with_rouge.csv'\n",
    "update_csv_with_rouge_scores(input_csv, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac8d0e6a-7f1e-4452-b588-43cadaabf1d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:8000/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_response\u001b[39m(query, mongo_data):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "\"model.py\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url = \"http://localhost:8000/v1\", api_key = \"token\")\n",
    "\n",
    "def model_response(query, mongo_data):\n",
    "    prompt = f\"\"\"    \n",
    "            Answer the question in a natural human-like manner. \n",
    "            Answer the question : {query} using the given context : {mongo_data} in less than 100 words.\n",
    "            Summarize the whole answer in a paragraph and do not return unnecessary explainations.\n",
    "            \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "            model = \"Meta-Llama-3.1-8B-Instruct-quantized.w4a16/\",\n",
    "            messages = [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a chatbot who answers the exact question\"},\n",
    "                        {\"role\":\"user\", \"content\": prompt}\n",
    "                        ]\n",
    "            )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba82410-2ffa-47df-9e19-e546e2f85b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.53.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Downloading openai-1.53.0-py3-none-any.whl (387 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.1/387.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.7.0-cp312-cp312-macosx_11_0_arm64.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, openai\n",
      "Successfully installed jiter-0.7.0 openai-1.53.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"feature_extraction.py\"\n",
    "import json\n",
    "from transformers import pipeline\n",
    "from transformers import pipeline, DebertaV2Tokenizor\n",
    "from get_schema import single_sub_keys\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"nli-deberta-v3-large\")\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"nli-deberta-v3-large\", tokenizer=tokenizer, device = \"cpu\")\n",
    "\n",
    "\n",
    "def obtain_nested_data(query, best_keywords):\n",
    "    # Obtain 2nd level keys\n",
    "    nested_data = single_sub_keys()\n",
    "    best_keywords_with_sub_keys = {}\n",
    "    for k, v in nested_data.items():\n",
    "        if k not in best_keywords:\n",
    "            continue\n",
    "        if v == []:\n",
    "            best_keywords_with_sub_keys[k] = []\n",
    "            continue\n",
    "        sub_data = classifier(query, v)[\"labels\"][:2]\n",
    "        best_keywords_with_sub_keys[k] = sub_data\n",
    "    return best_keywords_with_sub_keys\n",
    "\n",
    "\n",
    "def using_zero_shot(query):\n",
    "    keywords, descriptions = [], [] \n",
    "    \n",
    "    # Read values from metadata\n",
    "    with open(\"../metadata.json\") as f:\n",
    "        metadata = json.load(f)\n",
    "        reverse_metadata = {values:key for key, values in metadata.items()}\n",
    "    \n",
    "    best_descriptions = classifier(query, list(reverse_metadata.keys()))[\"labels\"][:2]\n",
    "    best_keywords = [reverse_metadata[desc] for desc in best_descriptions]\n",
    "    return best_keywords\n",
    "\n",
    "\n",
    "def using_rouge_similarity(query):\n",
    "    print(f\"The input query : {query}\")\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "     \n",
    "    # Read values from metadata\n",
    "    with open(\"../metadata.json\") as f:\n",
    "        metadata = json.load(f)\n",
    "    modified_keys = {\" \".join(val.split(\"_\")):val for val in metadata.keys()}\n",
    "    best_keys = []\n",
    "\n",
    "    for k, v in modified_keys.items():\n",
    "        score = scorer.score(k, query)\n",
    "        if score[\"rouge1\"].recall + score[\"rouge2\"].recall>=1:\n",
    "            best_keys.append(v)\n",
    "    return best_keys\n",
    "\n",
    "def main_feature(query):\n",
    "    #query = \"give the test scenarios for financial decisions user story.\"\n",
    "    best_keywords1 = using_zero_shot(query)\n",
    "    best_keywords2 = using_rouge_similarity(query)\n",
    "    best_keywords_with_sub_keys = obtain_nested_data(query, best_keywords1+best_keywords2)\n",
    "    print(\"The most improtant features are :\",best_keywords_with_sub_keys)\n",
    "    return best_keywords_with_sub_keys\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f87bde-8069-4d9b-8aa1-166dcd4f6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"get_schema.py\"\n",
    "\n",
    "import json\n",
    "from collections import deque\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to the MongoDB server\n",
    "client = MongoClient(\"mongodb://localhost:27018/\")\n",
    "\n",
    "# Select the database and collection\n",
    "db = client['OrgqrS1HZ']\n",
    "collection = db['userStories']\n",
    "# Retrieve a sample of documents\n",
    "sample_docs = collection.find_one()\n",
    "\n",
    "\n",
    "def data_recursion():\n",
    "    res_values = []\n",
    "\n",
    "    def extract_keys_bfs(data):\n",
    "        keys = []\n",
    "        queue = deque([(data, '')])\n",
    "\n",
    "        while queue:\n",
    "            current_dict, parent_key = queue.popleft()\n",
    "            for key, value in current_dict.items():\n",
    "\n",
    "                new_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "                keys.append(new_key)\n",
    "                if isinstance(value, dict):\n",
    "                    queue.append((value, new_key))\n",
    "                elif isinstance(value, list) and all(isinstance(i, dict) for i in value):\n",
    "                    for item in value:\n",
    "                        queue.append((item, new_key))\n",
    "                else:\n",
    "                    res_values.append(f\"{new_key} : \" + str(value))\n",
    "\n",
    "        return keys\n",
    "\n",
    "    result = extract_keys_bfs(sample_docs)\n",
    "    return result\n",
    "\n",
    "\n",
    "def single_sub_keys():\n",
    "    with open(\"../metadata.json\") as f:\n",
    "        data = json.load(f)\n",
    "    metadata_keys = data.keys()\n",
    "    \n",
    "    result = {}\n",
    "\n",
    "    for k,v in sample_docs.items():\n",
    "        if k in metadata_keys:\n",
    "            if type(sample_docs[k]) == dict:\n",
    "                result[k] = list(sample_docs[k].keys())\n",
    "            else:\n",
    "                result[k] = [] \n",
    "    return(result)\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    #data_recursion()\n",
    "    single_sub_keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
