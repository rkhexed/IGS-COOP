{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80954cd-6ee9-4b81-aa50-8e5eceb35ffc",
   "metadata": {},
   "source": [
    "File directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d01f7-de76-4257-8a6b-e2e2715e15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "drwxrwxr-x 8 staging_server staging_server 4096 Nov  7 11:23 .\n",
    "drwxrwxr-x 8 staging_server staging_server 4096 Nov  5 16:38 ..\n",
    "drwxrwxr-x 8 staging_server staging_server 4096 Nov  6 14:38 .git\n",
    "-rw-rw-r-- 1 staging_server staging_server  490 Nov  6 09:28 .gitignore\n",
    "drwxrwxr-x 2 staging_server staging_server 4096 Nov  7 11:23 __pycache__\n",
    "drwxrwxr-x 3 staging_server staging_server 4096 Nov  5 16:26 bart-large-mnli\n",
    "drwxrwxr-x 2 staging_server staging_server 4096 Nov  7 12:05 data\n",
    "drwxrwxr-x 3 staging_server staging_server 4096 Nov  5 16:27 dpr-ctx_encoder-single-nq-base\n",
    "-rw-rw-r-- 1 staging_server staging_server 2329 Nov  6 10:37 feature_extraction.py\n",
    "-rw-rw-r-- 1 staging_server staging_server 1659 Nov  6 14:38 get_schema.py\n",
    "-rw-rw-r-- 1 staging_server staging_server 5823 Nov  6 11:35 main.py\n",
    "-rw-rw-r-- 1 staging_server staging_server  310 Nov  5 16:20 metadata.json\n",
    "-rw-rw-r-- 1 staging_server staging_server 1133 Nov  6 12:16 model.py\n",
    "drwxrwxr-x 3 staging_server staging_server 4096 Nov  5 16:28 nli-deberta-v3-large\n",
    "-rw-rw-r-- 1 staging_server staging_server 2461 Nov  5 16:28 requirements.txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4140390-c685-427d-aed9-d076b4798aca",
   "metadata": {},
   "source": [
    "Requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fce252-9ec0-48ab-a7ff-4a1c091ff4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nvidia-cufft-cu12==11.0.2.54\n",
    "nvidia-curand-cu12==10.3.2.106\n",
    "nvidia-cusolver-cu12==11.4.5.107\n",
    "nvidia-cusparse-cu12==12.1.0.106\n",
    "nvidia-nccl-cu12==2.20.5\n",
    "nvidia-nvjitlink-cu12==12.6.77\n",
    "nvidia-nvtx-cu12==12.1.105\n",
    "onnxruntime==1.19.2\n",
    "openai==1.51.1\n",
    "orjson==3.10.7\n",
    "packaging==24.1\n",
    "pandas==1.5.3\n",
    "peft==0.5.0\n",
    "pillow==10.4.0\n",
    "propcache==0.2.0\n",
    "protobuf==5.28.2\n",
    "psutil==6.0.0\n",
    "pyarrow==18.0.0\n",
    "pyarrow-hotfix==0.6\n",
    "pydantic==2.9.2\n",
    "pydantic-settings==2.5.2\n",
    "pydantic_core==2.23.4\n",
    "pymilvus==2.4.7\n",
    "pymongo==4.9.2\n",
    "python-dateutil==2.9.0.post0\n",
    "python-dotenv==1.0.1\n",
    "pytz==2024.2\n",
    "PyYAML==6.0.2\n",
    "regex==2023.12.25\n",
    "requests==2.32.3\n",
    "requests-toolbelt==1.0.0\n",
    "rouge_score==0.1.2\n",
    "safetensors==0.4.5\n",
    "scikit-learn==1.5.2\n",
    "scipy==1.14.1\n",
    "sentence-transformers==3.2.0\n",
    "sentencepiece==0.2.0\n",
    "six==1.16.0\n",
    "sniffio==1.3.1\n",
    "soupsieve==2.6\n",
    "SQLAlchemy==2.0.35\n",
    "sympy==1.13.3\n",
    "tenacity==8.5.0\n",
    "threadpoolctl==3.5.0\n",
    "tokenizers==0.19.1\n",
    "torch==2.4.1\n",
    "tqdm==4.66.5\n",
    "transformers==4.44.2\n",
    "trec-car-tools==2.6\n",
    "triton==3.0.0\n",
    "typing-inspect==0.9.0\n",
    "typing_extensions==4.12.2\n",
    "ujson==5.10.0\n",
    "unlzw3==0.2.2\n",
    "urllib3==2.2.3\n",
    "warc3-wet==0.2.5\n",
    "warc3-wet-clueweb09==0.2.5\n",
    "xxhash==3.5.0\n",
    "yarl==1.14.0\n",
    "zlib-state==0.1.9\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e901f67-9f57-4fa9-be8b-03b9ea24db2f",
   "metadata": {},
   "source": [
    "model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b310c141-6762-4ee9-9731-8133c8a82766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url = \"http://localhost:8000/v1\", api_key = \"token\")\n",
    "\n",
    "def model_response(query, mongo_data):\n",
    "    if not mongo_data:\n",
    "        return \"<start> The data is not present in the database. <end>\"\n",
    "\n",
    "    prompt = f\"\"\"    \n",
    "            Follow the below instructions -\n",
    "            1) Answer the question in a natural human-like manner. \n",
    "            2) Use only the context to answer the question.\n",
    "            3) The question : {query} \n",
    "            4) The context : {mongo_data} \n",
    "            5) Respond clearly summarizing the answer in less than 100 words.\n",
    "            6) Add <start> before the acutal response and <end> after the response.\n",
    "            \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "            model = \"Meta-Llama-3.1-8B-Instruct-quantized.w4a16/\",\n",
    "            messages = [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a chatbot who answers the question, do not suggest reponses.\"},\n",
    "                        {\"role\":\"user\", \"content\": prompt}\n",
    "                        ]\n",
    "            )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90513fbe-8d2f-474b-b706-d7ccdbff2852",
   "metadata": {},
   "source": [
    "metadata.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5880f-7fb2-4ac2-bf9c-fd006780b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "        \"acceptance_criteria\":\"acceptance criteria, requirements, specific conditions, clarity\", \n",
    "        \"assumptions\":\"assumptions, dependencies\", \n",
    "        \"ambiguities\":\"ambiguities, vague, missing details\", \n",
    "        \"mind_maps\":\"visualizations, mind map, hierarchy\", \n",
    "        \"test_scenarios\":\"test scenarios, edge cases, test coverage\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca9dde-40dc-45d4-ae11-da33ec134972",
   "metadata": {},
   "source": [
    "main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e67849-7da0-42a7-9b80-70b80d6bcd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, model\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "import re, sys\n",
    "from bson.objectid import ObjectId\n",
    "from FlagEmbedding import FlagReranker\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "from feature_extraction import main_feature\n",
    "from model import model_response\n",
    "\n",
    "\n",
    "# Initialize MongoDB, Milvus Vector DB, Reranker\n",
    "mongodb_uri = \"mongodb://localhost:27018\"\n",
    "embedding_fn = model.DefaultEmbeddingFunction()\n",
    "milvus_client = MilvusClient(\"data/milvus_demo.db\")\n",
    "reranker = FlagReranker('BAAI/bge-reranker-v2-m3', query_max_length=256, passage_max_length=512, use_fp16=True, devices=['cpu'])\n",
    "\n",
    "\n",
    "# Create the vector DB\n",
    "def user_stories_db(database_name, collection_name, milvus_collection_name):\n",
    "    mongo_client = MongoClient(mongodb_uri)\n",
    "    db = mongo_client[database_name]\n",
    "    collection = db[collection_name]\n",
    "    documents = collection.find()\n",
    "\n",
    "    milvus_client.drop_collection(collection_name=milvus_collection_name)\n",
    "    milvus_client.create_collection(collection_name=milvus_collection_name, dimension=768)\n",
    "\n",
    "    story_data, complete_data = [], []\n",
    "\n",
    "    # Iterate over the MongoDB data\n",
    "    for doc in tqdm(documents):\n",
    "        try:\n",
    "            if \"refined\" not in doc or not doc[\"refined\"]:\n",
    "                doc[\"refined\"] = \" \"\n",
    "        \n",
    "            story_data.append(doc[\"story\"]+doc[\"refined\"])\n",
    "            complete_data.append({\"text\":doc[\"story\"]+doc[\"refined\"], \"id\":doc[\"_id\"]})\n",
    "        except:\n",
    "            print(\"Error with schema\")\n",
    "    # Convert the data to vectors\n",
    "    vectors = embedding_fn.encode_documents(story_data)\n",
    "    data = [{\"id\":i, \"data_id\":complete_data[i][\"id\"], \"vector\":vectors[i], \"text\":complete_data[i][\"text\"]} for i in range(len(vectors))]\n",
    "    \n",
    "    # Store the vector in Milvus\n",
    "    milvus_client.insert(collection_name = milvus_collection_name, data = data)\n",
    "\n",
    "def retrieve_user_stories(query, milvus_collection_name, threshold):\n",
    "    query_vectors = embedding_fn.encode_queries([query])\n",
    "    results = milvus_client.search(collection_name = milvus_collection_name, params = {\"metric_type\":\"COSINE\"}, data=query_vectors, \n",
    "            output_fields=[\"data_id\", \"text\", \"id\"])    \n",
    "    \n",
    "    retrived_documents = []\n",
    "    mongo_ids = []\n",
    "\n",
    "    # Get list of Docs and IDs from MongoDB\n",
    "    for i in range(len(results[0])):\n",
    "        # Filter data based on Vector similarity score threshold\n",
    "        if results[0][i][\"distance\"]>threshold:\n",
    "            retrived_documents.append(results[0][i][\"entity\"][\"text\"])\n",
    "            mongo_ids.append(results[0][i][\"entity\"][\"data_id\"])\n",
    "    \n",
    "    #print(retrived_documents)\n",
    "\n",
    "    # Obtain reranker score\n",
    "    data = [[query, doc] for doc in retrived_documents]\n",
    "    rank_scores = reranker.compute_score(data, normalize=True)\n",
    "\n",
    "    # Obtain rouge score\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = [scorer.score(query, doc.lower().replace(\"user\",\"\").replace(\"story\",\"\")) for doc in retrived_documents]\n",
    "    \n",
    "    # Filter based on reranker and rouge score\n",
    "    filtered_mongo_ids = [mongo_ids[idx] for idx, score in enumerate(rank_scores) if score>threshold or rouge_scores[idx][\"rougeL\"].recall>threshold]\n",
    "    print(\"Number of matching user story\", len(filtered_mongo_ids))\n",
    "    return filtered_mongo_ids\n",
    "\n",
    "\n",
    "def metadata_retrieval(database_name, collection_name, query, mongo_user_story_ids):\n",
    "    main_app_keys = main_feature(query) #closest_features(query)\n",
    "    \"\"\"\n",
    "    query_keys = [\"story\"] + main_app_keys\n",
    "    projection1 = {field: 1 for field in query_keys}\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the basic MongoQuery Dynamically\n",
    "    projection2 = {}\n",
    "    for field, subfields in main_app_keys.items():\n",
    "        if subfields:\n",
    "            for subfield in subfields:\n",
    "                projection2[f\"{field}.{subfield}\"] = 1\n",
    "        else:\n",
    "            projection2[f\"{field}\"] = 1\n",
    "        projection2[\"story\"] = 1 \n",
    "        projection2[\"refined\"] = 1\n",
    "    print(\"The mongoquery : \", projection2)\n",
    "    \n",
    "    # Use the mongo queries on the identified user story IDs\n",
    "    def match_mongo():\n",
    "        chunk_data = []\n",
    "        mongo_client = MongoClient(mongodb_uri)\n",
    "        db = mongo_client[database_name]\n",
    "        collection = db[collection_name]\n",
    "        \n",
    "        stories = collection.find({ '_id': { '$in':  mongo_user_story_ids} }, projection2)\n",
    "        \n",
    "\n",
    "        for i in stories:\n",
    "            temp_data = \"\"\n",
    "            for k in i.keys():\n",
    "                if k==\"_id\" or k==\"status\":\n",
    "                    continue\n",
    "                if k == \"story\":\n",
    "                    temp_data += f\"User story - {i[k]} \\t\"\n",
    "                if k==\"refined\":\n",
    "                    temp_data += f\"Refined User story - {i[k]} \\t\"\n",
    "                value = re.sub(r'[^a-zA-Z0-9\\s]',\"\", str(i[k]))\n",
    "                temp_data += f\"{k.upper()} - {value}. \\t\"\n",
    "            #print(temp_data,i[\"_id\"])\n",
    "            chunk_data.append(temp_data)\n",
    "        \n",
    "        return chunk_data\n",
    "\n",
    "    chunks = match_mongo()\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def main():\n",
    "    database_name = \"OrgqrS1HZ\"\n",
    "    collection_name = \"userStories\"\n",
    "    milvus_collection_name = \"temp\" \n",
    "    check = \"T\"\n",
    "    # Get the user story IDs from Mongo DB\n",
    "    #user_stories_db(database_name, collection_name, milvus_collection_name)\n",
    "    \n",
    "    while check==\"T\":\n",
    "        query = input(\"Enter query : \")\n",
    "        mongo_user_story_ids = retrieve_user_stories(query, milvus_collection_name, 0.2)\n",
    "        mongo_user_story_ids = list(set(mongo_user_story_ids[:5])) # Take first 5 unique IDs\n",
    "\n",
    "        # Get keys from metadata base on query\n",
    "        chunk_data = metadata_retrieval(database_name, collection_name, query, mongo_user_story_ids) \n",
    "        #print(\"The chunked data is :\",chunk_data) \n",
    "\n",
    "        # Get Model Response\n",
    "        response = model_response(query, \"\\n\".join(chunk_data))\n",
    "        print(\"Model response:\\n\",response)\n",
    "        \n",
    "        check = input(\"Continue [T/F] : \")\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b3fd1-6f46-4994-b014-87ccb81186e6",
   "metadata": {},
   "source": [
    "get_schema.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67293a-b88d-46cf-aab9-0f8e4ed2315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import deque\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to the MongoDB server\n",
    "client = MongoClient(\"mongodb://localhost:27018/\")\n",
    "\n",
    "# Select the database and collection\n",
    "db = client['OrgqrS1HZ']\n",
    "collection = db['userStories']\n",
    "# Retrieve a sample of documents\n",
    "sample_docs = collection.find_one()\n",
    "\n",
    "\n",
    "def data_recursion():\n",
    "    res_values = []\n",
    "\n",
    "    def extract_keys_bfs(data):\n",
    "        keys = []\n",
    "        queue = deque([(data, '')])\n",
    "\n",
    "        while queue:\n",
    "            current_dict, parent_key = queue.popleft()\n",
    "            for key, value in current_dict.items():\n",
    "\n",
    "                new_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "                keys.append(new_key)\n",
    "                if isinstance(value, dict):\n",
    "                    queue.append((value, new_key))\n",
    "                elif isinstance(value, list) and all(isinstance(i, dict) for i in value):\n",
    "                    for item in value:\n",
    "                        queue.append((item, new_key))\n",
    "                else:\n",
    "                    res_values.append(f\"{new_key} : \" + str(value))\n",
    "\n",
    "        return keys\n",
    "    \n",
    "    result = extract_keys_bfs(sample_docs)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def single_sub_keys():\n",
    "    with open(\"metadata.json\") as f:\n",
    "        data = json.load(f)\n",
    "    metadata_keys = data.keys()\n",
    "    \n",
    "    result = {}\n",
    "\n",
    "    for main_key,v in sample_docs.items():\n",
    "        if main_key in metadata_keys:\n",
    "            if type(sample_docs[main_key]) == dict:\n",
    "                result[main_key] =  list(sample_docs[main_key].keys())\n",
    "            else:\n",
    "                result[main_key] = [] \n",
    "\n",
    "    return(result)\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    #data_recursion()\n",
    "    single_sub_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6068f-0529-4228-bf0c-0cccb43a0fa5",
   "metadata": {},
   "source": [
    "feature_extraction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43086d80-f00d-43ed-99ac-56b212b9c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "from transformers import pipeline, DebertaV2Tokenizer\n",
    "from get_schema import single_sub_keys\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"nli-deberta-v3-large\")\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"nli-deberta-v3-large\", tokenizer=tokenizer, device = \"cpu\")\n",
    "\n",
    "\n",
    "def obtain_nested_data(query, best_keywords):\n",
    "    # Obtain 2nd level keys\n",
    "    nested_data = single_sub_keys()\n",
    "    best_keywords_with_sub_keys = {}\n",
    "    for k, v in nested_data.items():\n",
    "        if k not in best_keywords:\n",
    "            continue\n",
    "        if v == []:\n",
    "            best_keywords_with_sub_keys[k] = []\n",
    "            continue\n",
    "        sub_data = classifier(query, v)[\"labels\"][:2]\n",
    "        best_keywords_with_sub_keys[k] = sub_data\n",
    "    return best_keywords_with_sub_keys\n",
    "\n",
    "\n",
    "def using_zero_shot(query):\n",
    "    keywords, descriptions = [], [] \n",
    "    \n",
    "    # Read values from metadata\n",
    "    with open(\"metadata.json\") as f:\n",
    "        metadata = json.load(f)\n",
    "        reverse_metadata = {values:key for key, values in metadata.items()}\n",
    "    \n",
    "    best_descriptions = classifier(query, list(reverse_metadata.keys()))[\"labels\"][:2]\n",
    "    best_keywords = [reverse_metadata[desc] for desc in best_descriptions]\n",
    "    return best_keywords\n",
    "\n",
    "\n",
    "# Use rouge to obtain the required features\n",
    "def using_rouge_similarity(query):\n",
    "    print(f\"The input query : {query}\")\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "     \n",
    "    # Read values from metadata\n",
    "    with open(\"metadata.json\") as f:\n",
    "        metadata = json.load(f)\n",
    "    modified_keys = {\" \".join(val.split(\"_\")):val for val in metadata.keys()}\n",
    "    best_keys = []\n",
    "\n",
    "    for k, v in modified_keys.items():\n",
    "        score = scorer.score(k, query)\n",
    "        if score[\"rouge1\"].recall + score[\"rouge2\"].recall>=1:\n",
    "            best_keys.append(v)\n",
    "    return best_keys\n",
    "\n",
    "\n",
    "def main_feature(query):\n",
    "    #query = \"give the test scenarios for financial decisions user story.\"\n",
    "    best_keywords1 = using_zero_shot(query)\n",
    "    best_keywords2 = using_rouge_similarity(query)\n",
    "    best_keywords_with_sub_keys = obtain_nested_data(query, best_keywords1+best_keywords2)\n",
    "    print(\"The most improtant features are :\",best_keywords_with_sub_keys)\n",
    "    return best_keywords_with_sub_keys\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
